{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "import duckdb\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a31596",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './train.parquet'\n",
    "test_path = './test.parquet'\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "df = con.query(f\"\"\"(SELECT *\n",
    "                        FROM parquet_scan('{train_path}')\n",
    "                        WHERE binds = 0\n",
    "                        ORDER BY random()\n",
    "                        LIMIT 30000)\n",
    "                        UNION ALL\n",
    "                        (SELECT *\n",
    "                        FROM parquet_scan('{train_path}')\n",
    "                        WHERE binds = 1\n",
    "                        ORDER BY random()\n",
    "                        LIMIT 30000)\"\"\").df()\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33622f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f801fc04",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d618ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def molecule_to_graph(smiles):\n",
    "    molecule = Chem.MolFromSmiles(smiles)\n",
    "    if molecule is None:\n",
    "        return None\n",
    "\n",
    "    atoms = molecule.GetAtoms()\n",
    "    bonds = molecule.GetBonds()\n",
    "\n",
    "    node_features = torch.tensor([atom.GetAtomicNum() for atom in atoms], dtype=torch.float).unsqueeze(1)\n",
    "    \n",
    "    edge_index = []\n",
    "    edge_features = []\n",
    "    for bond in bonds:\n",
    "        start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        bond_type = bond.GetBondTypeAsDouble()\n",
    "        # Append forward and backward directions\n",
    "        edge_index.extend([(start, end), (end, start)])\n",
    "        edge_features.extend([bond_type, bond_type])  # Same feature for both directions\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_features = torch.tensor(edge_features, dtype=torch.float).unsqueeze(1)  # Ensure it has the right shape\n",
    "\n",
    "    return Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb04c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "smiles = 'CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1'\n",
    "graph_data = molecule_to_graph(smiles)\n",
    "if graph_data:\n",
    "    print(graph_data)\n",
    "else:\n",
    "    print(\"Invalid SMILES string.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac88db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def molecule_to_graph(smiles, protein_name, protein_to_idx, target_value):\n",
    "    molecule = Chem.MolFromSmiles(smiles)\n",
    "    if molecule is None:\n",
    "        return None\n",
    "\n",
    "    atoms = molecule.GetAtoms()\n",
    "    bonds = molecule.GetBonds()\n",
    "\n",
    "    # Node features: Atomic number\n",
    "    node_features = [atom.GetAtomicNum() for atom in atoms]\n",
    "    node_features = torch.tensor(node_features, dtype=torch.float).unsqueeze(1)\n",
    "    \n",
    "    # Edge indices and features\n",
    "    edge_index = []\n",
    "    edge_features = []\n",
    "    for bond in bonds:\n",
    "        start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        edge_index.extend([(start, end), (end, start)])\n",
    "        edge_features.extend([bond.GetBondTypeAsDouble(), bond.GetBondTypeAsDouble()])\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_features = torch.tensor(edge_features, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "    protein_idx = protein_to_idx[protein_name]\n",
    "\n",
    "    return Data(x=node_features, edge_index=edge_index, edge_attr=edge_features, protein_idx=protein_idx, y=torch.tensor([target_value], dtype=torch.float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e62d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' has a column 'molecule_smiles' containing SMILES strings\n",
    "protein_to_idx = {name: idx for idx, name in enumerate(df['protein_name'].unique())}\n",
    "# Assuming df has a 'binds' column with target values\n",
    "data_list = [\n",
    "    molecule_to_graph(row['molecule_smiles'], row['protein_name'], protein_to_idx, row['binds'])\n",
    "    for index, row in df.iterrows()\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b0957",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example DataFrame setup\n",
    "df = pd.DataFrame({\n",
    "    'molecule_smiles': ['CCO', 'CCC', 'CCN'],  # example SMILES\n",
    "    'protein_name': ['sEH', 'BRD4', 'HSA']\n",
    "})\n",
    "\n",
    "# Create a mapping from protein names to indices\n",
    "protein_to_idx = {name: idx for idx, name in enumerate(df['protein_name'].unique())}\n",
    "\n",
    "# Convert DataFrame rows to graph data\n",
    "data_list = [molecule_to_graph(row['molecule_smiles'], row['protein_name'], protein_to_idx) for index, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca43cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2048a7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "\n",
    "# Assuming molecule_to_graph is correctly implemented as previously discussed\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_protein_types, embedding_dim=10):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GATConv(num_features, 16, heads=8)\n",
    "        self.conv2 = GATConv(16 * 8, 32)\n",
    "        self.protein_embedding = torch.nn.Embedding(num_protein_types, embedding_dim)\n",
    "        self.fc1 = torch.nn.Linear(32 + embedding_dim, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 1)  # Output layer for regression\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch, protein_idx = data.x, data.edge_index, data.batch, data.protein_idx\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)  # Graph-level features for each molecule in the batch\n",
    "        protein_embed = self.protein_embedding(protein_idx)\n",
    "        x = torch.cat([x, protein_embed], dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# DataFrame setup, assume df and protein_to_idx are defined as you've done\n",
    "\n",
    "# Convert DataFrame rows to graph data and include target values if available\n",
    "#data_list = [molecule_to_graph(row['molecule_smiles'], row['protein_name'], protein_to_idx) for index, row in df.iterrows()]\n",
    "loader = DataLoader(data_list, batch_size=32, shuffle=True)\n",
    "\n",
    "# Instantiate the model\n",
    "model = GNN(num_features=1, num_protein_types=3, embedding_dim=10)  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Training Loop\n",
    "epochs = 30  # Define the number of epochs\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, batch.y)  # Ensure batch.y is correctly set as target values\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c125b1d",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20843b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_molecule_to_graph(smiles, protein_name, protein_to_idx):\n",
    "    molecule = Chem.MolFromSmiles(smiles)\n",
    "    if molecule is None:\n",
    "        return None\n",
    "\n",
    "    atoms = molecule.GetAtoms()\n",
    "    bonds = molecule.GetBonds()\n",
    "\n",
    "    # Node features: Atomic number\n",
    "    node_features = [atom.GetAtomicNum() for atom in atoms]\n",
    "    node_features = torch.tensor(node_features, dtype=torch.float).unsqueeze(1)\n",
    "    \n",
    "    # Edge indices and features\n",
    "    edge_index = []\n",
    "    edge_features = []\n",
    "    for bond in bonds:\n",
    "        start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        edge_index.extend([(start, end), (end, start)])\n",
    "        edge_features.extend([bond.GetBondTypeAsDouble(), bond.GetBondTypeAsDouble()])\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_features = torch.tensor(edge_features, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "    protein_idx = protein_to_idx[protein_name]\n",
    "\n",
    "    return Data(x=node_features, edge_index=edge_index, edge_attr=edge_features, protein_idx=protein_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ee5646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch\n",
    "\n",
    "# Assuming your model is defined somewhere as `model`\n",
    "train_path = './train.parquet'\n",
    "test_path = './test.parquet'\n",
    "output_file = './submission.csv'\n",
    "\n",
    "# Read the test.parquet file into a pandas DataFrame\n",
    "# If you really meant to use a CSV, ignore this conversion\n",
    "if os.path.exists('./test.parquet'):\n",
    "    df_test = pd.read_parquet(test_path)\n",
    "else:\n",
    "    df_test = pd.read_csv('./test.csv')  # Backup if parquet is not available\n",
    "\n",
    "# Create a mapping from protein names to indices\n",
    "protein_to_idx = {name: idx for idx, name in enumerate(df_test['protein_name'].unique())}\n",
    "\n",
    "\n",
    "# Convert DataFrame rows to graph data\n",
    "test_data_list = [test_molecule_to_graph(row['molecule_smiles'], row['protein_name'], protein_to_idx) for index, row in df_test.iterrows()]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b4ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch\n",
    "# Load data into DataLoader\n",
    "test_loader = DataLoader(test_data_list, batch_size=32, shuffle=False)\n",
    "\n",
    "# Set model to evaluation mode and predict\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    for data in test_loader:\n",
    "        output = model(data)\n",
    "        # Assuming output needs to be sigmoid-transformed to represent probabilities\n",
    "        predicted_probabilities = torch.sigmoid(output)\n",
    "        predictions.extend(predicted_probabilities.detach().cpu().numpy())\n",
    "\n",
    "# Prepare and save output DataFrame\n",
    "output_df = pd.DataFrame({\n",
    "    'id': df_test['id'],\n",
    "    'binds': [prob[0] for prob in predictions]  # Flatten probabilities if necessary\n",
    "})\n",
    "output_df.to_csv(output_file, index=False, mode='a', header=not os.path.exists(output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9cd157",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch\n",
    "test_loader = DataLoader(test_data_list, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    for data in test_loader:\n",
    "        output = model(data)  # Make predictions\n",
    "        #predicted_probabilities = torch.sigmoid(output)  # Apply sigmoid to get probabilities if your model outputs logits\n",
    "        predictions.extend(output)  # \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "output_df = pd.DataFrame({\n",
    "    'id': df_test['id'],  # Ensure df_test has an 'id' column\n",
    "    'binds': predictions\n",
    "})\n",
    "\n",
    "# Specify the path to your output file\n",
    "output_file = 'submission.csv'\n",
    "\n",
    "# Save to CSV, appending if file exists, otherwise write new file with header\n",
    "import os\n",
    "output_df.to_csv(output_file, index=False, mode='a', header=not os.path.exists(output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5b65a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysmiles import read_smiles\n",
    "import networkx as nx\n",
    "    \n",
    "smiles = 'C12=C3C4=C5C6=C1C7=C8C9=C1C%10=C%11C(=C29)C3=C2C3=C4C4=C5C5=C9C6=C7C6=C7C8=C1C1=C8C%10=C%10C%11=C2C2=C3C3=C4C4=C5C5=C%11C%12=C(C6=C95)C7=C1C1=C%12C5=C%11C4=C3C3=C5C(=C81)C%10=C23'\n",
    "mol = read_smiles(smiles)\n",
    "    \n",
    "# atom vector (C only)\n",
    "print(mol.nodes(data='element'))\n",
    "# adjacency matrix\n",
    "print(nx.to_numpy_matrix(mol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be76d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, 32)\n",
    "        self.fc = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)  # Average pooling\n",
    "        x = self.fc(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81ed164",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [Data(...)]  # Create a list of Data objects from your dataset\n",
    "loader = DataLoader(data_list, batch_size=32, shuffle=True)\n",
    "\n",
    "# Model, optimizer, and loss function\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(20):\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40978d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
