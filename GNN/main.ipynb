{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "import duckdb\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7a31596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9172d56e0b747bda9bb05a5fa2f96e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_path = './train.parquet'\n",
    "test_path = './test.parquet'\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "df = con.query(f\"\"\"(SELECT *\n",
    "                        FROM parquet_scan('{train_path}')\n",
    "                        WHERE binds = 0\n",
    "                        ORDER BY random()\n",
    "                        LIMIT 30000)\n",
    "                        UNION ALL\n",
    "                        (SELECT *\n",
    "                        FROM parquet_scan('{train_path}')\n",
    "                        WHERE binds = 1\n",
    "                        ORDER BY random()\n",
    "                        LIMIT 30000)\"\"\").df()\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33622f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>buildingblock1_smiles</th>\n",
       "      <th>buildingblock2_smiles</th>\n",
       "      <th>buildingblock3_smiles</th>\n",
       "      <th>molecule_smiles</th>\n",
       "      <th>protein_name</th>\n",
       "      <th>binds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134382410</td>\n",
       "      <td>O=C(Nc1c(Br)cc(F)cc1C(=O)O)OCC1c2ccccc2-c2ccccc21</td>\n",
       "      <td>Cc1cc(O)cc(C)c1N</td>\n",
       "      <td>Cc1sc(CN)nc1C(C)C</td>\n",
       "      <td>Cc1cc(O)cc(C)c1Nc1nc(NCc2nc(C(C)C)c(C)s2)nc(Nc...</td>\n",
       "      <td>sEH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23794434</td>\n",
       "      <td>CCS(=O)(=O)c1cc(C(=O)O)c(OC)cc1NC(=O)OCC1c2ccc...</td>\n",
       "      <td>Nc1ccc(F)nc1</td>\n",
       "      <td>CC(C)(C)OC(=O)N1CCN(c2ccccc2N)CC1</td>\n",
       "      <td>CCS(=O)(=O)c1cc(C(=O)N[Dy])c(OC)cc1Nc1nc(Nc2cc...</td>\n",
       "      <td>BRD4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100275550</td>\n",
       "      <td>O=C(N[C@@H](Cc1ccc(I)cc1)C(=O)O)OCC1c2ccccc2-c...</td>\n",
       "      <td>CC(C)c1nnc([C@H]2C[C@H](CN)[C@H](O)C2)[nH]1</td>\n",
       "      <td>C=C(Cl)CN.Cl</td>\n",
       "      <td>C=C(Cl)CNc1nc(NC[C@H]2C[C@H](c3nnc(C(C)C)[nH]3...</td>\n",
       "      <td>HSA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42258805</td>\n",
       "      <td>CS(=O)(=O)c1ccc(C(=O)O)c(NC(=O)OCC2c3ccccc3-c3...</td>\n",
       "      <td>Nc1cc(Cl)cnc1Cl</td>\n",
       "      <td>Nc1ccc2ncoc2c1</td>\n",
       "      <td>CS(=O)(=O)c1ccc(C(=O)N[Dy])c(Nc2nc(Nc3ccc4ncoc...</td>\n",
       "      <td>HSA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189604502</td>\n",
       "      <td>O=C(Nc1ccc(C(=O)O)cc1Cl)OCC1c2ccccc2-c2ccccc21</td>\n",
       "      <td>CC(C)(C)OC(=O)n1ncc2cc(N)ccc21</td>\n",
       "      <td>Nc1ccc(Cl)c(F)c1</td>\n",
       "      <td>CC(C)(C)OC(=O)n1ncc2cc(Nc3nc(Nc4ccc(Cl)c(F)c4)...</td>\n",
       "      <td>sEH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                              buildingblock1_smiles  \\\n",
       "0  134382410  O=C(Nc1c(Br)cc(F)cc1C(=O)O)OCC1c2ccccc2-c2ccccc21   \n",
       "1   23794434  CCS(=O)(=O)c1cc(C(=O)O)c(OC)cc1NC(=O)OCC1c2ccc...   \n",
       "2  100275550  O=C(N[C@@H](Cc1ccc(I)cc1)C(=O)O)OCC1c2ccccc2-c...   \n",
       "3   42258805  CS(=O)(=O)c1ccc(C(=O)O)c(NC(=O)OCC2c3ccccc3-c3...   \n",
       "4  189604502     O=C(Nc1ccc(C(=O)O)cc1Cl)OCC1c2ccccc2-c2ccccc21   \n",
       "\n",
       "                         buildingblock2_smiles  \\\n",
       "0                             Cc1cc(O)cc(C)c1N   \n",
       "1                                 Nc1ccc(F)nc1   \n",
       "2  CC(C)c1nnc([C@H]2C[C@H](CN)[C@H](O)C2)[nH]1   \n",
       "3                              Nc1cc(Cl)cnc1Cl   \n",
       "4               CC(C)(C)OC(=O)n1ncc2cc(N)ccc21   \n",
       "\n",
       "               buildingblock3_smiles  \\\n",
       "0                  Cc1sc(CN)nc1C(C)C   \n",
       "1  CC(C)(C)OC(=O)N1CCN(c2ccccc2N)CC1   \n",
       "2                       C=C(Cl)CN.Cl   \n",
       "3                     Nc1ccc2ncoc2c1   \n",
       "4                   Nc1ccc(Cl)c(F)c1   \n",
       "\n",
       "                                     molecule_smiles protein_name  binds  \n",
       "0  Cc1cc(O)cc(C)c1Nc1nc(NCc2nc(C(C)C)c(C)s2)nc(Nc...          sEH      0  \n",
       "1  CCS(=O)(=O)c1cc(C(=O)N[Dy])c(OC)cc1Nc1nc(Nc2cc...         BRD4      0  \n",
       "2  C=C(Cl)CNc1nc(NC[C@H]2C[C@H](c3nnc(C(C)C)[nH]3...          HSA      0  \n",
       "3  CS(=O)(=O)c1ccc(C(=O)N[Dy])c(Nc2nc(Nc3ccc4ncoc...          HSA      0  \n",
       "4  CC(C)(C)OC(=O)n1ncc2cc(Nc3nc(Nc4ccc(Cl)c(F)c4)...          sEH      0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f801fc04",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17d618ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def molecule_to_graph(smiles):\n",
    "    molecule = Chem.MolFromSmiles(smiles)\n",
    "    if molecule is None:\n",
    "        return None\n",
    "\n",
    "    atoms = molecule.GetAtoms()\n",
    "    bonds = molecule.GetBonds()\n",
    "\n",
    "    node_features = torch.tensor([atom.GetAtomicNum() for atom in atoms], dtype=torch.float).unsqueeze(1)\n",
    "    \n",
    "    edge_index = []\n",
    "    edge_features = []\n",
    "    for bond in bonds:\n",
    "        start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        bond_type = bond.GetBondTypeAsDouble()\n",
    "        # Append forward and backward directions\n",
    "        edge_index.extend([(start, end), (end, start)])\n",
    "        edge_features.extend([bond_type, bond_type])  # Same feature for both directions\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_features = torch.tensor(edge_features, dtype=torch.float).unsqueeze(1)  # Ensure it has the right shape\n",
    "\n",
    "    return Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb04c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "smiles = 'CC(C)(C)c1ccc2occ(CC(=O)Nc3ccccc3F)c2c1'\n",
    "graph_data = molecule_to_graph(smiles)\n",
    "if graph_data:\n",
    "    print(graph_data)\n",
    "else:\n",
    "    print(\"Invalid SMILES string.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ac88db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def molecule_to_graph(smiles, protein_name, protein_to_idx, target_value):\n",
    "    molecule = Chem.MolFromSmiles(smiles)\n",
    "    if molecule is None:\n",
    "        return None\n",
    "\n",
    "    atoms = molecule.GetAtoms()\n",
    "    bonds = molecule.GetBonds()\n",
    "\n",
    "    # Node features: Atomic number\n",
    "    node_features = [atom.GetAtomicNum() for atom in atoms]\n",
    "    node_features = torch.tensor(node_features, dtype=torch.float).unsqueeze(1)\n",
    "    \n",
    "    # Edge indices and features\n",
    "    edge_index = []\n",
    "    edge_features = []\n",
    "    for bond in bonds:\n",
    "        start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        edge_index.extend([(start, end), (end, start)])\n",
    "        edge_features.extend([bond.GetBondTypeAsDouble(), bond.GetBondTypeAsDouble()])\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_features = torch.tensor(edge_features, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "    protein_idx = protein_to_idx[protein_name]\n",
    "\n",
    "    return Data(x=node_features, edge_index=edge_index, edge_attr=edge_features, protein_idx=protein_idx, y=torch.tensor([target_value], dtype=torch.float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e62d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' has a column 'molecule_smiles' containing SMILES strings\n",
    "protein_to_idx = {name: idx for idx, name in enumerate(df['protein_name'].unique())}\n",
    "# Assuming df has a 'binds' column with target values\n",
    "data_list = [\n",
    "    molecule_to_graph(row['molecule_smiles'], row['protein_name'], protein_to_idx, row['binds'])\n",
    "    for index, row in df.iterrows()\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b0957",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example DataFrame setup\n",
    "df = pd.DataFrame({\n",
    "    'molecule_smiles': ['CCO', 'CCC', 'CCN'],  # example SMILES\n",
    "    'protein_name': ['sEH', 'BRD4', 'HSA']\n",
    "})\n",
    "\n",
    "# Create a mapping from protein names to indices\n",
    "protein_to_idx = {name: idx for idx, name in enumerate(df['protein_name'].unique())}\n",
    "\n",
    "# Convert DataFrame rows to graph data\n",
    "data_list = [molecule_to_graph(row['molecule_smiles'], row['protein_name'], protein_to_idx) for index, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6dca43cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[40, 1], edge_index=[2, 86], edge_attr=[86, 1], y=[1], protein_idx=0),\n",
       " Data(x=[52, 1], edge_index=[2, 112], edge_attr=[112, 1], y=[1], protein_idx=1),\n",
       " Data(x=[41, 1], edge_index=[2, 88], edge_attr=[88, 1], y=[1], protein_idx=2),\n",
       " Data(x=[40, 1], edge_index=[2, 88], edge_attr=[88, 1], y=[1], protein_idx=2),\n",
       " Data(x=[44, 1], edge_index=[2, 96], edge_attr=[96, 1], y=[1], protein_idx=0)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2048a7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyuqing/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.24480946362018585\n",
      "Epoch 2, Loss: 0.25336194038391113\n",
      "Epoch 3, Loss: 0.2429126501083374\n",
      "Epoch 4, Loss: 0.2547247111797333\n",
      "Epoch 5, Loss: 0.24511493742465973\n",
      "Epoch 6, Loss: 0.24903278052806854\n",
      "Epoch 7, Loss: 0.2483302652835846\n",
      "Epoch 8, Loss: 0.24753382802009583\n",
      "Epoch 9, Loss: 0.2521287202835083\n",
      "Epoch 10, Loss: 0.2491285651922226\n",
      "Epoch 11, Loss: 0.2520098388195038\n",
      "Epoch 12, Loss: 0.24957674741744995\n",
      "Epoch 13, Loss: 0.24408774077892303\n",
      "Epoch 14, Loss: 0.2460491806268692\n",
      "Epoch 15, Loss: 0.25408220291137695\n",
      "Epoch 16, Loss: 0.24818657338619232\n",
      "Epoch 17, Loss: 0.2490234524011612\n",
      "Epoch 18, Loss: 0.24931392073631287\n",
      "Epoch 19, Loss: 0.2509426176548004\n",
      "Epoch 20, Loss: 0.2503223121166229\n",
      "Epoch 21, Loss: 0.2528747022151947\n",
      "Epoch 22, Loss: 0.24766354262828827\n",
      "Epoch 23, Loss: 0.24757221341133118\n",
      "Epoch 24, Loss: 0.2533261775970459\n",
      "Epoch 25, Loss: 0.24662800133228302\n",
      "Epoch 26, Loss: 0.2649485468864441\n",
      "Epoch 27, Loss: 0.24842503666877747\n",
      "Epoch 28, Loss: 0.2521907687187195\n",
      "Epoch 29, Loss: 0.24902714788913727\n",
      "Epoch 30, Loss: 0.24978965520858765\n",
      "Epoch 31, Loss: 0.2502690255641937\n",
      "Epoch 32, Loss: 0.26704737544059753\n",
      "Epoch 33, Loss: 0.2544447183609009\n",
      "Epoch 34, Loss: 0.25617629289627075\n",
      "Epoch 35, Loss: 0.2495199590921402\n",
      "Epoch 36, Loss: 0.2620527446269989\n",
      "Epoch 37, Loss: 0.25096696615219116\n",
      "Epoch 38, Loss: 0.25545573234558105\n",
      "Epoch 39, Loss: 0.25062060356140137\n",
      "Epoch 40, Loss: 0.2510643005371094\n",
      "Epoch 41, Loss: 0.25249072909355164\n",
      "Epoch 42, Loss: 0.251571387052536\n",
      "Epoch 43, Loss: 0.25113093852996826\n",
      "Epoch 44, Loss: 0.2639721930027008\n",
      "Epoch 45, Loss: 0.2530120015144348\n",
      "Epoch 46, Loss: 0.2490205466747284\n",
      "Epoch 47, Loss: 0.24249215424060822\n",
      "Epoch 48, Loss: 0.2525007128715515\n",
      "Epoch 49, Loss: 0.2488841861486435\n",
      "Epoch 50, Loss: 0.2513543963432312\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "\n",
    "# Assuming molecule_to_graph is correctly implemented as previously discussed\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_protein_types, embedding_dim=10):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GATConv(num_features, 16, heads=8)\n",
    "        self.conv2 = GATConv(16 * 8, 32)\n",
    "        self.protein_embedding = torch.nn.Embedding(num_protein_types, embedding_dim)\n",
    "        self.fc1 = torch.nn.Linear(32 + embedding_dim, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 1)  # Output layer for regression\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch, protein_idx = data.x, data.edge_index, data.batch, data.protein_idx\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)  # Graph-level features for each molecule in the batch\n",
    "        protein_embed = self.protein_embedding(protein_idx)\n",
    "        x = torch.cat([x, protein_embed], dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# DataFrame setup, assume df and protein_to_idx are defined as you've done\n",
    "\n",
    "# Convert DataFrame rows to graph data and include target values if available\n",
    "#data_list = [molecule_to_graph(row['molecule_smiles'], row['protein_name'], protein_to_idx) for index, row in df.iterrows()]\n",
    "loader = DataLoader(data_list, batch_size=32, shuffle=True)\n",
    "\n",
    "# Instantiate the model\n",
    "model = GNN(num_features=1, num_protein_types=3, embedding_dim=10)  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Training Loop\n",
    "epochs = 50  # Define the number of epochs\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, batch.y)  # Ensure batch.y is correctly set as target values\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58fbcbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def molecule_to_graph(molecule_smiles, protein_feature):\n",
    "    molecule = Chem.MolFromSmiles(molecule_smiles)\n",
    "    atoms = molecule.GetAtoms()\n",
    "    bonds = molecule.GetBonds()\n",
    "\n",
    "    node_features = torch.tensor([atom.GetAtomicNum() for atom in atoms], dtype=torch.float).unsqueeze(1)\n",
    "    edge_index = torch.tensor([(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()) for bond in bonds], dtype=torch.long).t().contiguous()\n",
    "\n",
    "    return Data(x=node_features, edge_index=edge_index, protein_features=protein_feature)\n",
    "molecule_to_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba056f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c125b1d",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20843b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_molecule_to_graph(smiles, protein_name, protein_to_idx):\n",
    "    molecule = Chem.MolFromSmiles(smiles)\n",
    "    if molecule is None:\n",
    "        return None\n",
    "\n",
    "    atoms = molecule.GetAtoms()\n",
    "    bonds = molecule.GetBonds()\n",
    "\n",
    "    # Node features: Atomic number\n",
    "    node_features = [atom.GetAtomicNum() for atom in atoms]\n",
    "    node_features = torch.tensor(node_features, dtype=torch.float).unsqueeze(1)\n",
    "    \n",
    "    # Edge indices and features\n",
    "    edge_index = []\n",
    "    edge_features = []\n",
    "    for bond in bonds:\n",
    "        start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        edge_index.extend([(start, end), (end, start)])\n",
    "        edge_features.extend([bond.GetBondTypeAsDouble(), bond.GetBondTypeAsDouble()])\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_features = torch.tensor(edge_features, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "    protein_idx = protein_to_idx[protein_name]\n",
    "\n",
    "    return Data(x=node_features, edge_index=edge_index, edge_attr=edge_features, protein_idx=protein_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6398ecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "train_path = './train.parquet'\n",
    "test_path = './test.parquet'\n",
    "# Process the test.parquet file chunk by chunk\n",
    "test_file = './test.csv'\n",
    "output_file = './submission.csv'  \n",
    "\n",
    "# Read the test.parquet file into a pandas DataFrame\n",
    "df_test = pd.read_csv(test_file)\n",
    "\n",
    "# Create a mapping from protein names to indices\n",
    "test_protein_to_idx = {name: idx for idx, name in enumerate(df_test['protein_name'].unique())}\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e54126c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '_cached_attr'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-73be0c3a2410>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert DataFrame rows to graph data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_data_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtest_molecule_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'molecule_smiles'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'protein_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_protein_to_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-73be0c3a2410>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert DataFrame rows to graph data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_data_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtest_molecule_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'molecule_smiles'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'protein_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_protein_to_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-c5e3943ee439>\u001b[0m in \u001b[0;36mtest_molecule_to_graph\u001b[0;34m(smiles, protein_name, protein_to_idx)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprotein_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprotein_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprotein_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotein_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotein_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, edge_index, edge_attr, y, pos, time, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0medge_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0mpropobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpropobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpropobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0mpropobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36mx\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pop_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m_pop_cache\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pop_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cached_attr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             raise AttributeError(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Convert DataFrame rows to graph data\n",
    "test_data_list = [test_molecule_to_graph(row['molecule_smiles'], row['protein_name'], test_protein_to_idx) for index, row in df_test.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3ee5646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyuqing/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch\n",
    "\n",
    "# Assuming your model is defined somewhere as `model`\n",
    "train_path = './train.parquet'\n",
    "test_path = './test.parquet'\n",
    "output_file = './submission.csv'\n",
    "\n",
    "# Read the test.parquet file into a pandas DataFrame\n",
    "# If you really meant to use a CSV, ignore this conversion\n",
    "if os.path.exists('./test.parquet'):\n",
    "    df_test = pd.read_parquet(test_path)\n",
    "else:\n",
    "    df_test = pd.read_csv('./test.csv')  # Backup if parquet is not available\n",
    "\n",
    "# Create a mapping from protein names to indices\n",
    "protein_to_idx = {name: idx for idx, name in enumerate(df_test['protein_name'].unique())}\n",
    "\n",
    "# Assuming test_molecule_to_graph is similar to your earlier defined function\n",
    "def test_molecule_to_graph(smiles, protein_name, protein_to_idx):\n",
    "    # Dummy implementation here; replace with your actual function\n",
    "    return Data(x=torch.randn(50, 1), edge_index=torch.randint(0, 50, (2, 100)), protein_idx=protein_to_idx[protein_name])\n",
    "\n",
    "# Convert DataFrame rows to graph data\n",
    "test_data_list = [test_molecule_to_graph(row['molecule_smiles'], row['protein_name'], protein_to_idx) for index, row in df_test.iterrows()]\n",
    "\n",
    "# Load data into DataLoader\n",
    "test_loader = DataLoader(test_data_list, batch_size=32, shuffle=False)\n",
    "\n",
    "# Set model to evaluation mode and predict\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    for data in test_loader:\n",
    "        output = model(data)\n",
    "        # Assuming output needs to be sigmoid-transformed to represent probabilities\n",
    "        predicted_probabilities = torch.sigmoid(output)\n",
    "        predictions.extend(predicted_probabilities.detach().cpu().numpy())\n",
    "\n",
    "# Prepare and save output DataFrame\n",
    "output_df = pd.DataFrame({\n",
    "    'id': df_test['id'],\n",
    "    'binds': [prob[0] for prob in predictions]  # Flatten probabilities if necessary\n",
    "})\n",
    "output_df.to_csv(output_file, index=False, mode='a', header=not os.path.exists(output_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e9cd157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyuqing/opt/anaconda3/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array length 60000 does not match index length 1674896",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-eeb93458e29e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m output_df = pd.DataFrame({\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Ensure df_test has an 'id' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m'binds'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    666\u001b[0m                     \u001b[0;34mf\"length {len(index)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m                 )\n\u001b[0;32m--> 668\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: array length 60000 does not match index length 1674896"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch\n",
    "test_loader = DataLoader(test_data_list, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    for data in test_loader:\n",
    "        output = model(data)  # Make predictions\n",
    "        #predicted_probabilities = torch.sigmoid(output)  # Apply sigmoid to get probabilities if your model outputs logits\n",
    "        predictions.extend(output)  # \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "output_df = pd.DataFrame({\n",
    "    'id': df_test['id'],  # Ensure df_test has an 'id' column\n",
    "    'binds': predictions\n",
    "})\n",
    "\n",
    "# Specify the path to your output file\n",
    "output_file = 'submission.csv'\n",
    "\n",
    "# Save to CSV, appending if file exists, otherwise write new file with header\n",
    "import os\n",
    "output_df.to_csv(output_file, index=False, mode='a', header=not os.path.exists(output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a5b65a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'C'), (1, 'C'), (2, 'C'), (3, 'C'), (4, 'C'), (5, 'C'), (6, 'C'), (7, 'C'), (8, 'C'), (9, 'C'), (10, 'C'), (11, 'C'), (12, 'C'), (13, 'C'), (14, 'C'), (15, 'C'), (16, 'C'), (17, 'C'), (18, 'C'), (19, 'C'), (20, 'C'), (21, 'C'), (22, 'C'), (23, 'C'), (24, 'C'), (25, 'C'), (26, 'C'), (27, 'C'), (28, 'C'), (29, 'C'), (30, 'C'), (31, 'C'), (32, 'C'), (33, 'C'), (34, 'C'), (35, 'C'), (36, 'C'), (37, 'C'), (38, 'C'), (39, 'C'), (40, 'C'), (41, 'C'), (42, 'C'), (43, 'C'), (44, 'C'), (45, 'C'), (46, 'C'), (47, 'C'), (48, 'C'), (49, 'C'), (50, 'C'), (51, 'C'), (52, 'C'), (53, 'C'), (54, 'C'), (55, 'C'), (56, 'C'), (57, 'C'), (58, 'C'), (59, 'C')]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from pysmiles import read_smiles\n",
    "import networkx as nx\n",
    "    \n",
    "smiles = 'C12=C3C4=C5C6=C1C7=C8C9=C1C%10=C%11C(=C29)C3=C2C3=C4C4=C5C5=C9C6=C7C6=C7C8=C1C1=C8C%10=C%10C%11=C2C2=C3C3=C4C4=C5C5=C%11C%12=C(C6=C95)C7=C1C1=C%12C5=C%11C4=C3C3=C5C(=C81)C%10=C23'\n",
    "mol = read_smiles(smiles)\n",
    "    \n",
    "# atom vector (C only)\n",
    "print(mol.nodes(data='element'))\n",
    "# adjacency matrix\n",
    "print(nx.to_numpy_matrix(mol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73f368f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-f6b64f9da788>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Match output dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-f6b64f9da788>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprotein_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprotein_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprotein_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure it is 2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotein_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 3"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "# Model definition\n",
    "class MoleculeProteinGNN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_protein_features, num_classes):\n",
    "        super(MoleculeProteinGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 128)\n",
    "        self.conv2 = GCNConv(128, 64)\n",
    "        self.fc1 = torch.nn.Linear(64 + num_protein_features, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        protein_features = data.protein_features\n",
    "        if protein_features.dim() == 1:\n",
    "            protein_features = protein_features.unsqueeze(0)  # Ensure it is 2D\n",
    "        x = torch.cat((x, protein_features), dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Example Data preparation\n",
    "# Assume data_list is correctly prepared and contains Data objects with .x, .edge_index, .batch, and .protein_features\n",
    "train_loader = DataLoader(data_list[:int(0.8 * len(data_list))], batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(data_list[int(0.8 * len(data_list)):], batch_size=32, shuffle=False)\n",
    "\n",
    "# Model instantiation\n",
    "model = MoleculeProteinGNN(num_node_features=1, num_protein_features=3, num_classes=1)  # Adjust as per actual feature counts\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for data in train_loader:\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = criterion(output, data.y.float().unsqueeze(1))  # Match output dimensions\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Evaluation loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        output = model(data)\n",
    "        predictions = (torch.sigmoid(output) > 0.5).float()  # Convert logits to binary predictions\n",
    "        correct += (predictions == data.y.unsqueeze(1)).sum().item()  # Ensure dimensions match\n",
    "        total += data.y.size(0)\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be76d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, 32)\n",
    "        self.fc = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)  # Average pooling\n",
    "        x = self.fc(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f81ed164",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_node_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-b1779f670505>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Model, optimizer, and loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-011bfc827a7d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_node_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_node_features' is not defined"
     ]
    }
   ],
   "source": [
    "data_list = [Data(...)]  # Create a list of Data objects from your dataset\n",
    "loader = DataLoader(data_list, batch_size=32, shuffle=True)\n",
    "\n",
    "# Model, optimizer, and loss function\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58479e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Process the test.parquet file chunk by chunk\n",
    "test_file = './test.csv'\n",
    "output_file = 'submission.csv'  # Specify the path and filename for the output file\n",
    "\n",
    "# Read the test.parquet file into a pandas DataFrame\n",
    "for df_test in pd.read_csv(test_file, chunksize=100000):\n",
    "\n",
    "    # Generate ECFPs for the molecule_smiles\n",
    "    df_test['molecule'] = df_test['molecule_smiles'].apply(Chem.MolFromSmiles)\n",
    "    df_test['ecfp'] = df_test['molecule'].apply(smiles_to_ecfp)\n",
    "\n",
    "    # One-hot encode the protein_name\n",
    "    protein_onehot =  OneHotEncoder(sparse_output=False).transform(df_test['protein_name'].values.reshape(-1, 1))\n",
    "\n",
    "    # Combine ECFPs and one-hot encoded protein_name\n",
    "    X_test = [ecfp + protein for ecfp, protein in zip(df_test['ecfp'].tolist(), protein_onehot.tolist())]\n",
    "\n",
    "    # Predict the probabilities\n",
    "    probabilities = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Create a DataFrame with 'id' and 'probability' columns\n",
    "    output_df = pd.DataFrame({'id': df_test['id'], 'binds': probabilities})\n",
    "\n",
    "    # Save the output DataFrame to a CSV file\n",
    "    output_df.to_csv(output_file, index=False, mode='a', header=not os.path.exists(output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40978d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
